{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Dataset Processing\n",
    "\n",
    "This notebook can be used to load, evaluate, compare, refine and export hand-labeled tracking datasets \n",
    "\n",
    "*(Data must be annotated with the blender [**OmniTrax**](https://github.com/FabianPlum/OmniTrax) addon or [**blenderMotionExport**](https://github.com/FabianPlum/blenderMotionExport) or follow the convention of individual CSV files per tracked animal with explicit frame numbers)*\n",
    "\n",
    "First, let's load some packages and a few essential import / export functions from **Antrax_base.py** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# now for the file management fucntions\n",
    "from Antrax_base import import_tracks, display_video, get_exact_frame, extractPatches, display_patches, sortByDistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more information on how each function works, you can simply type it out followed by a question mark to display its docstring below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exp: Show the docstring of \"import_tracks\" by uncommenting the next line\n",
    "import_tracks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now specify the **location** of all **export folders** of tracks you wish to analyse. Simply add the folder path to the **export_paths** array and the location of the annotated video file. This is especially useful when comparing **human vs human** or **human vs machine** agreement regarding track annotation. You can also just provide a single export folder for analysis and visualisation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_paths = [\"example_ant_recording\"]\n",
    "video = \"../images/example_ant_recording.mp4\"\n",
    "\n",
    "# enter the number of annotated frames:\n",
    "tracked_frames = 1000\n",
    "\n",
    "# now we can load the captured video file and display it\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "# check the number of frames of the imported video file\n",
    "numFramesMax = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"The imported clip:\", video, \"has a total of\",numFramesMax ,\"frames.\\n\")\n",
    "\n",
    "# now let's load all tracks listed in the export_paths\n",
    "tracks = []\n",
    "for folder in export_paths:\n",
    "    # You can export all tracks into a single .csv file by setting \"export=True\"\n",
    "    tracks.append(import_tracks(folder, numFramesMax, export=True))\n",
    "    \n",
    "    # The following function is used to display the tracks you imported.\n",
    "    # You can press \"q\" while hovering over the displayed video to exit.\n",
    "    print(\"\\nDisplaying tracks loaded from:\", folder)\n",
    "    display_video(cap, tracks[-1], show=(0, tracked_frames), scale=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll plot the imported trajectories from each subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the resolution of the video file to automatically adjust the axis limits of the plot\n",
    "resolution = [int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))]\n",
    "\n",
    "def plot_tracks(tracks, title=\"\"):\n",
    "    # replace all zeros with None before plotting\n",
    "    tracks = tracks.astype(float)\n",
    "    tracks[tracks == 0] = None\n",
    "\n",
    "    for track in range(int((tracks.shape[-1] - 1) / 2)):\n",
    "        plt.plot(tracks[:tracked_frames,int(track*2 + 1)],tracks[:tracked_frames,int(track*2 + 2)])\n",
    "\n",
    "        plt.title(title)    \n",
    "        plt.xlabel(\"X axis [px]\")   \n",
    "        plt.ylabel(\"Y axis [px]\")\n",
    "        plt.xlim(0,resolution[0])\n",
    "        plt.ylim(0,resolution[1])\n",
    "    \n",
    "    plt.savefig(video.split(\".\")[0] + \"_all_tracks.svg\")\n",
    "    plt.show()\n",
    "    \n",
    "# plot all tracks    \n",
    "for count, annotator in enumerate(tracks):\n",
    "    num_tracks = int((annotator.shape[-1] - 1)/2)  \n",
    "    plot_tracks(tracks=annotator,title=\"all tracks of \" + export_paths[count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll match the **tracks** of **all annotators** based on their **proximity**. We'll iterate through all tracks of the first annotator and compute a similirity score based on the distance of each tracked instance, ignoring zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(track_1, track_2, matching_threshold=50):\n",
    "    # here we use the pixel distance as a metric of similarity\n",
    "    # the lower the pixel distance, thus similarity value, the higher the liklihood of two track belonging to the same ID\n",
    "    combined_distance = []\n",
    "    track_1 = track_1.astype(float)\n",
    "    track_2 = track_2.astype(float)\n",
    "    for frame, coords in enumerate(track_1):\n",
    "        if not np.array_equal(track_1[frame],[0,0]) and not np.array_equal(track_2[frame],[0,0]):\n",
    "            combined_distance.append(np.sqrt(np.power(track_1[frame,0] - track_2[frame,0],2) +\n",
    "                                             np.power(track_1[frame,1] - track_2[frame,1],2)))\n",
    "            \n",
    "    # now compute the similarity as the mean distance between the two tracks\n",
    "    if combined_distance:\n",
    "        similarity = np.round(np.mean(combined_distance), decimals=3)\n",
    "    else:\n",
    "        similarity = matching_threshold\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def match_tracks(tracks_a, tracks_b):\n",
    "    num_tracks_a = int((tracks_a.shape[1] - 1)/2)\n",
    "    num_tracks_b = int((tracks_b.shape[1] - 1)/2)\n",
    "    similarities = np.empty([num_tracks_a, num_tracks_b], dtype=float)\n",
    "    print(\"Similarity grid shape:\", similarities.shape, \"\\n\")\n",
    "    print(\"Computing similarities...\")\n",
    "\n",
    "    # compare all tracks of 2 annotators at a time and match them based on their mean euclidean distance\n",
    "    for a in range(similarities.shape[0]):\n",
    "        for b in range (similarities.shape[1]):\n",
    "            similarities[a,b] = get_similarity(track_1=tracks_a[:tracked_frames,a*2 + 1:a*2 + 3],\n",
    "                                               track_2=tracks_b[:tracked_frames,b*2 + 1:b*2 + 3],\n",
    "                                               matching_threshold = matching_threshold)\n",
    "\n",
    "    # record the indices of all likely matches and unmatched tracks\n",
    "    matched = []\n",
    "    unmatched_a = []\n",
    "    unmatched_b = np.arange(num_tracks_b)\n",
    "\n",
    "    for track_a, track_a_similarities in enumerate(similarities):\n",
    "        sim_max = np.argmin(track_a_similarities[np.nonzero(track_a_similarities)])\n",
    "        if track_a_similarities[sim_max] < matching_threshold:\n",
    "            matched.append([track_a,sim_max])\n",
    "            unmatched_b[sim_max] = 0\n",
    "            print(\"Track\", track_a, \"most likely corresponds to Track\", sim_max,\n",
    "                  \"with a mean euclidean distance [px] of\", track_a_similarities[sim_max])\n",
    "        else:\n",
    "            unmatched_a.append(track_a)\n",
    "            print(\"Track\", track_a, \"has no likely match.\")\n",
    "\n",
    "    # show list of matched tracks        \n",
    "    print(\"\\nmatched:\\n\",matched,\"\\n\")\n",
    "\n",
    "    if len(unmatched_a) > 0:\n",
    "        print(\"Unmatched tracks of\",export_paths[0],\": \\n\",unmatched_a,\"\\n\")\n",
    "    else:\n",
    "        print(\"All tracks of\",export_paths[0], \"have been matched!\\n\")\n",
    "\n",
    "    # create the final list of unmatched_b tracks\n",
    "    unmatched_b = unmatched_b[unmatched_b != 0]\n",
    "    if len(unmatched_b) > 0:\n",
    "        print(\"Unmatched tracks of\",export_paths[1],\": \\n\",unmatched_b,\"\\n\")\n",
    "    else:\n",
    "        print(\"All tracks of\",export_paths[1], \"have been matched!\\n\")\n",
    "\n",
    "    return matched, unmatched_a, unmatched_b\n",
    "\n",
    "\n",
    "def generate_ground_truth(tracks_a, tracks_b, matches, unmatched_a, unmatched_b, num_frames, \n",
    "                          iteration=0, ignore_unmatched=False):\n",
    "    # create array of the size of (num_frames x (frame + all_tracks(x,y)))\n",
    "    ground_truth = np.zeros([num_frames, 1 + 2 * (len(matches) + len(unmatched_a) + len(unmatched_b))])\n",
    "    \n",
    "    # add frame numers to the first column\n",
    "    frames = np.arange(1,num_frames + 1)\n",
    "    \n",
    "    ground_truth[:,0] = frames\n",
    "    \n",
    "    if iteration == 0:\n",
    "        print(\"Initial combination of tracks. All are weighted equally\")\n",
    "    else: \n",
    "        print(\"Iteration:\", iteration)\n",
    "        print(\"Additional tracks contribute with 1/\"+ str(iteration + 2),\"weight.\\n\")\n",
    "    \n",
    "    # now compute the weighted average for every matching track\n",
    "    for count, match in enumerate(matches):\n",
    "        for frame in range(ground_truth.shape[0]):\n",
    "            pos_a_x, pos_a_y = tracks_a[frame , 2 * match[0] + 1 : 2 * match[0] + 3]\n",
    "            pos_b_x, pos_b_y = tracks_b[frame , 2 * match[1] + 1 : 2 * match[1] + 3]\n",
    "            \n",
    "            pos_sum_x = pos_a_x * (1 + iteration) + pos_b_x\n",
    "            pos_sum_y = pos_a_y * (1 + iteration) + pos_b_y\n",
    "            \n",
    "            if pos_a_x != 0 and pos_b_x != 0:\n",
    "                ground_truth[frame,count * 2 + 1] = pos_sum_x / (2 + iteration)\n",
    "            else:\n",
    "                # only compute the average if both values are non-zero\n",
    "                # If one value is zero, only the other should contribute to the track\n",
    "                ground_truth[frame,count * 2 + 1] = pos_sum_x\n",
    "                \n",
    "            # repeat for the y-axis\n",
    "            \n",
    "            if pos_a_y != 0 and pos_b_y != 0:\n",
    "                ground_truth[frame,count * 2 + 2] = pos_sum_y / (2 + iteration)\n",
    "            else:\n",
    "                # only compute the average if both values are non-zero\n",
    "                # If one value is zero, only the other should contribute to the track\n",
    "                ground_truth[frame,count * 2 + 2] = pos_sum_y\n",
    "                \n",
    "    # add the remaining unmatched_a tracks\n",
    "    if len(unmatched_a) > 0:\n",
    "        for count, unmatched in enumerate(unmatched_a):\n",
    "            ground_truth[:,(count + len(matches)) * 2 + 1: (count + len(matches)) * 2 + 3] = tracks_a[\n",
    "                :tracked_frames,unmatched * 2 + 1 : unmatched * 2 + 3]\n",
    "    \n",
    "    # add the remaining unmatched_b tracks\n",
    "    if len(unmatched_b) > 0:\n",
    "        for count, unmatched in enumerate(unmatched_b):\n",
    "            ground_truth[:,(count + len(unmatched_a) + len(matches)) * 2 + 1: \n",
    "                         (count + len(unmatched_a) + len(matches)) * 2 + 3] = tracks_b[\n",
    "                :tracked_frames,unmatched * 2 + 1 : unmatched * 2 + 3]\n",
    "    \n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing **likely matching tracks** we can now combine them into **ground truth tracks**, which are a weighted average of all matching tracks. **Unmatched tracks** are added without modification. Then, we iteratively compare the current ground truth to further annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the matching threshold according to the track quality and resolution of the tracked footage\n",
    "matching_threshold = 50\n",
    "\n",
    "# compute a grid of similarities between all tracks\n",
    "\n",
    "if len(export_paths) > 1:\n",
    "    matched, unmatched_a, unmatched_b = match_tracks(tracks_a = tracks[0], tracks_b = tracks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(export_paths) > 1:\n",
    "    gt = generate_ground_truth(tracks_a=tracks[0], tracks_b=tracks[1], matches=matched, unmatched_a=unmatched_a, \n",
    "                          unmatched_b=unmatched_b, num_frames=tracked_frames, iteration=0)\n",
    "\n",
    "    print(\"Generated a total of\",int((gt.shape[-1] - 1) / 2),\"ground truth tracks.\")\n",
    "\n",
    "    display_video(cap, gt, show=(0, tracked_frames - 2), scale=0.3)\n",
    "\n",
    "    # plot resulting ground truth tracks\n",
    "    plot_tracks(tracks=gt, title=\"all ground truth tracks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated **ground truth tracks** can now be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_tracks(tracks,path=\"ground_truth\"):\n",
    "    tracks = tracks.astype(int)\n",
    "    np.savetxt(path + \".csv\", tracks, delimiter=\",\")\n",
    "    \n",
    "    print(\"Exported tracks successfully to\", path + \".csv\")\n",
    "\n",
    "if len(export_paths) > 1:\n",
    "    export_tracks(tracks=gt, path=\"ground_truth_\" + video.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also **import** existing ground truth files for evaluation or to add further annotators. When adding additional annotators, make sure to correctly set the iteration to weigh the influence of further tracks correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_ground_truth(path):\n",
    "    tracks = np.loadtxt(path, delimiter=\",\")\n",
    "    tracks = tracks.astype(int)\n",
    "    \n",
    "    print(\"Imported tracks successfully from\", path)\n",
    "    \n",
    "    return tracks\n",
    "\n",
    "if len(export_paths) > 1:\n",
    "    new_gt = import_ground_truth(path=\"ground_truth_\" + video.split(\".\")[0])\n",
    "else:\n",
    "    new_gt = import_ground_truth(path=\"example_ant_recording_all_tracks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derivative(tracks, time_step=1 / 30, verbose=False):\n",
    "    tracks_der = np.zeros([tracks.shape[0], int((tracks.shape[1] - 1) / 2)])\n",
    "    # convert tracks to float array\n",
    "    tracks_der = tracks_der.astype(float)\n",
    "\n",
    "    num_tracks = int((tracks.shape[1] - 1) / 2)\n",
    "    num_timeSteps = tracks.shape[0]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Computing derivative for\", num_tracks, \"tracks...\")\n",
    "\n",
    "    for t in range(num_timeSteps - 1):\n",
    "        # then retrieve all track centres at the given frame\n",
    "        track_centres = tracks[t, 1:]\n",
    "        track_centres_non_zero_ids = np.nonzero(track_centres)[0][::2]\n",
    "\n",
    "        if len(track_centres_non_zero_ids) != 0:\n",
    "\n",
    "            for track_orig in track_centres_non_zero_ids:\n",
    "                track = int((track_orig + 1) / 2)\n",
    "\n",
    "                # check that the next value is no zero\n",
    "                \n",
    "                try:\n",
    "                    if tracks[t + 1, track * 2 + 1] == 0 or tracks[t + 1, track * 2 + 2] == 0:\n",
    "                        continue\n",
    "\n",
    "                    tracks_der[t, track] = np.sqrt((tracks[t + 1, track * 2 + 1] -\n",
    "                                                    tracks[t, track * 2 + 1]) ** 2 +\n",
    "                                                   (tracks[t + 1, track * 2 + 2] -\n",
    "                                                    tracks[t, track * 2 + 2]) ** 2) / time_step\n",
    "                except IndexError:\n",
    "                    pass\n",
    "\n",
    "    return tracks_der\n",
    "\n",
    "\n",
    "def apply_moving_average(tracks, samples=3, padding_mode='valid', verbose=False):\n",
    "    tracks_ma = np.copy(tracks)\n",
    "    tracks_ma.astype(float)\n",
    "    num_tracks = int((tracks.shape[1] - 1) / 2)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Applying moving average of size\", samples, \"to\", num_tracks, \"tracks...\")\n",
    "    for t in range(num_tracks):\n",
    "        # apply smoothing only to areas where tracked subject is in view\n",
    "        # therefore, all zero entries must be ignored\n",
    "        track_temp_x = tracks[:, t * 2 + 1]\n",
    "        track_temp_y = tracks[:, t * 2 + 2]\n",
    "\n",
    "        nonzeroind = np.nonzero(track_temp_x)[0]\n",
    "\n",
    "        # the following code is bad and slow. But I don't care. There is a strange artifact in some exported tracks\n",
    "        # where there are sudden un-connected coordinates appearing outside the tracked area. So we find those and\n",
    "        # remove them. No matter the (compute) cost.\n",
    "\n",
    "        rm_ind = []\n",
    "\n",
    "        for ind, f in enumerate(nonzeroind):\n",
    "            if 0 < f < len(tracks) - 1:\n",
    "                if tracks[f, t * 2 + 1] != 0 and tracks[f - 1, t * 2 + 1] == 0 and tracks[f + 1, t * 2 + 1] == 0:\n",
    "                    rm_ind.append(ind)\n",
    "\n",
    "        nonzeroind = np.delete(nonzeroind, rm_ind)\n",
    "\n",
    "        track_x = np.convolve(track_temp_x[nonzeroind[0]:nonzeroind[-1] - samples], np.ones(samples) / samples,\n",
    "                              mode=padding_mode)\n",
    "        track_y = np.convolve(track_temp_y[nonzeroind[0]:nonzeroind[-1] - samples], np.ones(samples) / samples,\n",
    "                              mode=padding_mode)\n",
    "\n",
    "        tracks_ma[nonzeroind[0] + math.floor(samples / 2):nonzeroind[-1] - math.ceil(samples / 2) - samples + 1,\n",
    "        t * 2 + 1] = track_x\n",
    "        tracks_ma[nonzeroind[0] + math.floor(samples / 2):nonzeroind[-1] - math.ceil(samples / 2) - samples + 1,\n",
    "        t * 2 + 2] = track_y\n",
    "\n",
    "        # add back zeros\n",
    "    return tracks_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks_smoothed = apply_moving_average(new_gt, samples=1, padding_mode=\"valid\")\n",
    "tracks_velocity = get_derivative(tracks_smoothed)\n",
    "\n",
    "# plot smoothed ground truth tracks\n",
    "plot_tracks(tracks=tracks_smoothed, title=\"smoothed ground truth tracks\")\n",
    "\n",
    "# plot velocity profile of example ground truth tracks\n",
    "plt.plot(tracks_velocity[:,5:10])\n",
    "plt.title(\"example velocity profiles of smoothed tracks\")\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"velocity [px/s]\")\n",
    "plt.ylim(0,600)\n",
    "plt.xlim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap of ground truth tracks\n",
    "# first, combine all traccks into an array of X,Y coords\n",
    "tracks_compressed = np.array([], dtype=np.int64).reshape(0,2)\n",
    "for track in range(int((new_gt.shape[1] - 1)/2)):\n",
    "    tracks_compressed = np.vstack((tracks_compressed,new_gt[:,track * 2 + 1 : track * 2 + 3]))\n",
    "    \n",
    "# now remove all zero entries from the array to prevent the 0 bin from over saturating the plot\n",
    "tracks_compressed = tracks_compressed[~np.all(tracks_compressed == 0, axis=1)]\n",
    "    \n",
    "heatmap, xedges, yedges = np.histogram2d(tracks_compressed[:,0], tracks_compressed[:,1], \n",
    "                                         bins=(int(resolution[0]/50),int(resolution[1]/50)),\n",
    "                                         range=[[0,resolution[0]],[0,resolution[1]]])\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "from matplotlib.image import NonUniformImage\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "im = NonUniformImage(ax, interpolation='bilinear', extent=extent)\n",
    "xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "im.set_data(xcenters, ycenters, heatmap.T)\n",
    "ax.images.append(im)\n",
    "\n",
    "plt.xlabel(\"X axis [px]\")   \n",
    "plt.ylabel(\"Y axis [px]\")\n",
    "plt.xlim(0,resolution[0])\n",
    "plt.ylim(0,resolution[1])\n",
    "plt.title(\"heatmap of ground truth tracks\")\n",
    "plt.savefig(video.split(\".\")[0] + \"_heatmap_of_ground_truth_tracks.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
